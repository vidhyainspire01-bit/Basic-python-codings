{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f53af5e-91cd-48c6-bf5d-1372c31f1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score)\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 1/3\n",
    "\n",
    "# 0) Load + clean\n",
    "df = pd.read_csv(\"CKD.csv\")\n",
    "df = df.replace([\"?\", \"NA\", \"na\", \"NaN\", \"nan\", \"\"], np.nan)\n",
    "\n",
    "# 1) Target + features\n",
    "y = (df[\"classification\"] == \"yes\").astype(int)  # 1=yes, 0=no\n",
    "X = df.drop(columns=[\"classification\"])\n",
    "\n",
    "# 2) Train/test split (STRATIFY!)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Train-based IMPUTATION (simple & leakage-safe)\n",
    "num_cols = X_train_raw.select_dtypes(exclude=\"object\").columns\n",
    "cat_cols = X_train_raw.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# numeric -> median\n",
    "num_medians = X_train_raw[num_cols].median()\n",
    "X_train_raw[num_cols] = X_train_raw[num_cols].fillna(num_medians)\n",
    "X_test_raw[num_cols]  = X_test_raw[num_cols].fillna(num_medians)\n",
    "\n",
    "# categorical -> mode from train\n",
    "for c in cat_cols:\n",
    "    mode_val = X_train_raw[c].mode(dropna=True)\n",
    "    if len(mode_val) == 0:\n",
    "        # if an all-NaN cat col exists, fill with a placeholder\n",
    "        fillv = \"missing\"\n",
    "    else:\n",
    "        fillv = mode_val.iloc[0]\n",
    "    X_train_raw[c] = X_train_raw[c].fillna(fillv)\n",
    "    X_test_raw[c]  = X_test_raw[c].fillna(fillv)\n",
    "\n",
    "# 4) One-hot encode TRAIN, align TEST to TRAIN columns\n",
    "X_train = pd.get_dummies(X_train_raw, dtype=float, drop_first=True)\n",
    "X_test  = pd.get_dummies(X_test_raw,  dtype=float, drop_first=True)\n",
    "X_train, X_test = X_train.align(X_test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "# 5) Scaled copies (for models that like scaling)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 6) Helper: fit + evaluate\n",
    "def evaluate_classifier(name, estimator, param_grid, Xtr, ytr, Xte, yte, scoring=\"roc_auc\"):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    grid = GridSearchCV(estimator, param_grid, cv=cv, n_jobs=-1, verbose=1, scoring=scoring, refit=True)\n",
    "    grid.fit(Xtr, ytr)\n",
    "\n",
    "    best = grid.best_estimator_\n",
    "    y_pred = best.predict(Xte)\n",
    "    # get scores for ROC/PR AUC\n",
    "    if hasattr(best, \"decision_function\"):\n",
    "        y_score = best.decision_function(Xte)\n",
    "    elif hasattr(best, \"predict_proba\"):\n",
    "        y_score = best.predict_proba(Xte)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred  # fallback (rare)\n",
    "\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Best CV score (\", scoring, \"):\", grid.best_score_)\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(yte, y_pred))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(yte, y_pred))\n",
    "    print(\"Accuracy :\", accuracy_score(yte, y_pred))\n",
    "    print(\"Precision:\", precision_score(yte, y_pred))\n",
    "    print(\"Recall   :\", recall_score(yte, y_pred))\n",
    "    print(\"F1       :\", f1_score(yte, y_pred))\n",
    "    try:\n",
    "        print(\"ROC AUC  :\", roc_auc_score(yte, y_score))\n",
    "        print(\"PR  AUC  :\", average_precision_score(yte, y_score))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return best, grid.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26dc3783-c3a6-4c77-8fd3-1e0bd8d07d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 26 candidates, totalling 130 fits\n",
      "\n",
      "===== LogisticRegression =====\n",
      "Best CV score ( roc_auc ): 1.0\n",
      "Best params: {'C': np.float64(0.1), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Confusion matrix:\n",
      " [[50  0]\n",
      " [ 4 79]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        50\n",
      "           1       1.00      0.95      0.98        83\n",
      "\n",
      "    accuracy                           0.97       133\n",
      "   macro avg       0.96      0.98      0.97       133\n",
      "weighted avg       0.97      0.97      0.97       133\n",
      "\n",
      "Accuracy : 0.9699248120300752\n",
      "Precision: 1.0\n",
      "Recall   : 0.9518072289156626\n",
      "F1       : 0.9753086419753086\n",
      "ROC AUC  : 0.9995180722891566\n",
      "PR  AUC  : 0.9997165131112689\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "\n",
      "===== RandomForest =====\n",
      "Best CV score ( roc_auc ): 1.0\n",
      "Best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Confusion matrix:\n",
      " [[49  1]\n",
      " [ 1 82]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        50\n",
      "           1       0.99      0.99      0.99        83\n",
      "\n",
      "    accuracy                           0.98       133\n",
      "   macro avg       0.98      0.98      0.98       133\n",
      "weighted avg       0.98      0.98      0.98       133\n",
      "\n",
      "Accuracy : 0.9849624060150376\n",
      "Precision: 0.9879518072289156\n",
      "Recall   : 0.9879518072289156\n",
      "F1       : 0.9879518072289156\n",
      "ROC AUC  : 0.9995180722891566\n",
      "PR  AUC  : 0.9997114101846285\n"
     ]
    }
   ],
   "source": [
    "# 1) LOGISTIC REGRESSION \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "param_grid_lr = {\n",
    "    \"C\": np.logspace(-3, 3, 13),\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"penalty\": [\"l2\"],\n",
    "}\n",
    "best_lr, params_lr = evaluate_classifier(\n",
    "    \"LogisticRegression\",\n",
    "    lr, param_grid_lr,\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2) RANDOM FOREST \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\", n_jobs=-1)\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 5, 10, 15],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "best_rf, params_rf = evaluate_classifier(\n",
    "    \"RandomForest\",\n",
    "    rf, param_grid_rf,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e914df3-50fc-47e8-adf1-e68a98f81de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "\n",
      "===== DecisionTree =====\n",
      "Best CV score ( roc_auc ): 0.9711051693404634\n",
      "Best params: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\n",
      "Confusion matrix:\n",
      " [[48  2]\n",
      " [ 2 81]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.98      0.98      0.98        83\n",
      "\n",
      "    accuracy                           0.97       133\n",
      "   macro avg       0.97      0.97      0.97       133\n",
      "weighted avg       0.97      0.97      0.97       133\n",
      "\n",
      "Accuracy : 0.9699248120300752\n",
      "Precision: 0.9759036144578314\n",
      "Recall   : 0.9759036144578314\n",
      "F1       : 0.9759036144578314\n",
      "ROC AUC  : 0.9756626506024098\n",
      "PR  AUC  : 0.9771266510446963\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "\n",
      "===== kNN =====\n",
      "Best CV score ( roc_auc ): 1.0\n",
      "Best params: {'n_neighbors': 11, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "Confusion matrix:\n",
      " [[50  0]\n",
      " [ 9 74]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        50\n",
      "           1       1.00      0.89      0.94        83\n",
      "\n",
      "    accuracy                           0.93       133\n",
      "   macro avg       0.92      0.95      0.93       133\n",
      "weighted avg       0.94      0.93      0.93       133\n",
      "\n",
      "Accuracy : 0.9323308270676691\n",
      "Precision: 1.0\n",
      "Recall   : 0.891566265060241\n",
      "F1       : 0.9426751592356688\n",
      "ROC AUC  : 0.993012048192771\n",
      "PR  AUC  : 0.9948934245906536\n"
     ]
    }
   ],
   "source": [
    "# 3) DECISION TREE \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "param_grid_dt = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [None, 4, 6, 8, 10, 12],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "best_dt, params_dt = evaluate_classifier(\n",
    "    \"DecisionTree\",\n",
    "    dt, param_grid_dt,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "\n",
    "# 4) k-NEAREST NEIGHBORS \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": list(range(3, 32, 2)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2],  # 1=Manhattan, 2=Euclidean\n",
    "}\n",
    "best_knn, params_knn = evaluate_classifier(\n",
    "    \"kNN\",\n",
    "    knn, param_grid_knn,\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3be1db-1ae8-45ea-a508-ce2b3e968e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "\n",
      "===== GaussianNB =====\n",
      "Best CV score ( roc_auc ): 1.0\n",
      "Best params: {'var_smoothing': np.float64(1e-12)}\n",
      "\n",
      "Confusion matrix:\n",
      " [[49  1]\n",
      " [ 2 81]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        50\n",
      "           1       0.99      0.98      0.98        83\n",
      "\n",
      "    accuracy                           0.98       133\n",
      "   macro avg       0.97      0.98      0.98       133\n",
      "weighted avg       0.98      0.98      0.98       133\n",
      "\n",
      "Accuracy : 0.9774436090225563\n",
      "Precision: 0.9878048780487805\n",
      "Recall   : 0.9759036144578314\n",
      "F1       : 0.9818181818181818\n",
      "ROC AUC  : 0.9897590361445783\n",
      "PR  AUC  : 0.9878101465936793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) NAIVE BAYES (GaussianNB,\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# GaussianNB tolerates mixed (continuous + OHE) features; scaling is OK.\n",
    "gnb = GaussianNB()\n",
    "param_grid_gnb = {\n",
    "    \"var_smoothing\": np.logspace(-12, -6, 7)\n",
    "}\n",
    "best_gnb, params_gnb = evaluate_classifier(\n",
    "    \"GaussianNB\",\n",
    "    gnb, param_grid_gnb,\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e412ac81-9cec-4dec-afd0-d1542917834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp311-cp311-win_amd64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from xgboost) (1.16.0)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from catboost) (2.3.1)\n",
      "Collecting plotly (from catboost)\n",
      "  Downloading plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: six in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nishok\\miniconda3\\envs\\ml_env\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
      "  Downloading narwhals-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading xgboost-3.0.4-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 10.2/56.8 MB 58.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 58.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 35.1/56.8 MB 58.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 46.9/56.8 MB 58.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 59.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 56.6 MB/s eta 0:00:00\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 74.3 MB/s eta 0:00:00\n",
      "Downloading catboost-1.2.8-cp311-cp311-win_amd64.whl (102.5 MB)\n",
      "   ---------------------------------------- 0.0/102.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 12.6/102.5 MB 60.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 24.4/102.5 MB 61.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 36.4/102.5 MB 59.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 48.5/102.5 MB 59.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 60.3/102.5 MB 59.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 72.4/102.5 MB 59.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.9/102.5 MB 58.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.8/102.5 MB 59.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  102.2/102.5 MB 59.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 102.5/102.5 MB 54.0 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 9.8/9.8 MB 61.1 MB/s eta 0:00:00\n",
      "Downloading narwhals-2.1.1-py3-none-any.whl (389 kB)\n",
      "Installing collected packages: narwhals, graphviz, xgboost, plotly, lightgbm, catboost\n",
      "\n",
      "   ---------------------------------------- 0/6 [narwhals]\n",
      "   ---------------------------------------- 0/6 [narwhals]\n",
      "   ---------------------------------------- 0/6 [narwhals]\n",
      "   ---------------------------------------- 0/6 [narwhals]\n",
      "   ------ --------------------------------- 1/6 [graphviz]\n",
      "   ------------- -------------------------- 2/6 [xgboost]\n",
      "   ------------- -------------------------- 2/6 [xgboost]\n",
      "   ------------- -------------------------- 2/6 [xgboost]\n",
      "   ------------- -------------------------- 2/6 [xgboost]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------- ------------------- 3/6 [plotly]\n",
      "   -------------------------- ------------- 4/6 [lightgbm]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   --------------------------------- ------ 5/6 [catboost]\n",
      "   ---------------------------------------- 6/6 [catboost]\n",
      "\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21 lightgbm-4.6.0 narwhals-2.1.1 plotly-6.3.0 xgboost-3.0.4\n",
      "Fitting 5 folds for each of 12150 candidates, totalling 60750 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     10\u001b[39m xgb = XGBClassifier(\n\u001b[32m     11\u001b[39m     random_state=RANDOM_STATE,\n\u001b[32m     12\u001b[39m     tree_method=\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m param_grid_xgb = [\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# gbtree\u001b[39;00m\n\u001b[32m     20\u001b[39m     {\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     },\n\u001b[32m     43\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m best_xgb, params_xgb = \u001b[43mevaluate_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mXGBoost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid_xgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroc_auc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     49\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mevaluate_classifier\u001b[39m\u001b[34m(name, estimator, param_grid, Xtr, ytr, Xte, yte, scoring)\u001b[39m\n\u001b[32m     58\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=RANDOM_STATE)\n\u001b[32m     59\u001b[39m grid = GridSearchCV(estimator, param_grid, cv=cv, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m, scoring=scoring, refit=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m best = grid.best_estimator_\n\u001b[32m     63\u001b[39m y_pred = best.predict(Xte)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "!pip install xgboost lightgbm catboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "    # Handle mild imbalance\n",
    "    # class balance (pos = 1)\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "spw = neg / pos if pos else 1.0  \n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=spw,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "param_grid_xgb = [\n",
    "    # gbtree\n",
    "    {\n",
    "        \"booster\": [\"gbtree\"],\n",
    "        \"max_depth\": [3, 4, 5],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"subsample\": [0.7, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "        \"min_child_weight\": [1, 3, 5],\n",
    "        \"gamma\": [0, 1],\n",
    "    },\n",
    "    # dart\n",
    "    {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"max_depth\": [3, 4, 5],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"subsample\": [0.7, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.9, 1.0],\n",
    "        \"min_child_weight\": [1, 3, 5],\n",
    "        \"gamma\": [0, 1],\n",
    "        \"rate_drop\": [0.0, 0.1, 0.2],\n",
    "        \"skip_drop\": [0.0, 0.5],\n",
    "        \"normalize_type\": [\"tree\", \"forest\"],\n",
    "        \"sample_type\": [\"uniform\", \"weighted\"],\n",
    "    },\n",
    "]\n",
    "best_xgb, params_xgb = evaluate_classifier(\n",
    "    \"XGBoost\",\n",
    "    xgb, param_grid_xgb,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    scoring=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496355d6-1d57-40ea-b7f9-71e3af253a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
